---
title: "Project 3"
author: "Alissa Stover"
date: "3/14/2020"
output: github_document

---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

# Environment

## Import Libraries 

```{r, message=FALSE}
library(tidyverse) # for data import, manipulation, viz
```

## Import Data

We are importing a CSV file into R. The argument `n_max` is set to the number of rows of data we are provided (91). 

```{r, message=FALSE}
data <- read_csv("crime_v2.csv", n_max = 91)
```

# Exploratory Data Analysis

Let's take a visual check of our data. We have 91 observations and 25 columns. This is what we expected. 

```{r}
head(data)
dim(data)
```

All 25 columns are numeric. 

```{r}
str(data)
```

## The Where & When of these data 

It looks like we usually have 1 observation for each of the counties -- except for county #193. We do not have any missing values in the `county` column. 

```{r}
length(unique(data$county))
table(data$county, useNA = "always")
```

Having 2 observations for county #193 is surprising. We can see that these rows appear to be exact duplicates. 

```{r}
data %>% filter(county == 193)
```

We can see that `year` appears to be constant (which is expected). We also don't have any missing values for this column. We can drop this column in future data processing steps. 

```{r}
table(data$year, useNA = "always")
```

Based on the explorations above, we create a new dataframe that has dropped our superfluous column (`year`) and the superfluous row (duplicate of county 193). 

```{r}
data2 <- data %>% distinct() %>% select(-year)
```

Now we have 90 rows and 24 variables, with one observation per county.

```{r}
length(unique(data2$county)) == length(data2$county) # check 1 obs per county
str(data2) # examine dataframe 
```

## Missingness

We can see from the following that we don't have any missing data, which is good! 

```{r}
pct_miss <- data %>% map(~ mean(is.na(.)))
pct_miss
```

Save our clean dataset

```{r}
save(data2, file = "data_clean.rda")
```

## Identifying Key Variables 

To start prioritizing variables, here we group them into categories. 

The following variables appear to be related to our target (crime). The first (`crmte`) seems to be the most closely related and will likely be the target variable in our model. 

1) `crmrte`: crimes committed per person
2) `prbarr`: 'probability' of arrest
3) `prbconv`: 'probability' of conviction
4) `prbpris`: 'probability' of prison sentence

These variables are crime related, but would likely not be used as our target variable. The first (`mix`) is not something we could directly control via policy; the other 2 could provide actionable information. 

5) `mix`:	offense mix: face-to-face/other
6) `avgsen`:	avg. sentence, days
7) `polpc`:	police per capita

Since we are aiming to produce policy recommendations, the following variables may be helpful in our analysis but are not necessarily actionable. They describe county characteristics.

8) `county`:	county identifier
9) `density`:	people per sq. mile
10) `west`:	=1 if in western N.C.
11) `central`:	=1 if in central N.C.
12) `urban`:	=1 if in SMSA
13) `pctmin80`:	perc. minority, 1980
14) `pctymle`:	percent young male

The rest of the variables do describe things we could affect with policy. They all speak to wages for different sectors, except for `taxpc`.

15) `taxpc`:	tax revenue per capita
16) `wcon`:	weekly wage, construction
17) `wtuc`:	wkly wge, trns, util, commun
18) `wtrd`:	wkly wge, whlesle, retail trade
19) `wfir`:	wkly wge, fin, ins, real est
20) `wser`:	wkly wge, service industry
21) `wmfg`:	wkly wge, manufacturing
22) `wfed`:	wkly wge, fed employees
23) `wsta`:	wkly wge, state employees
24) `wloc`:	wkly wge, local gov emps


