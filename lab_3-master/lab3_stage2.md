Lab 3: Stage 2
================
Priscilla Burity, Oscar Linares, Alissa Stover
3/31/2020

Stage 2: Peer Feedback - Due at Live Session 13 In Stage 2, you will
provide feedback on another team’s draft report. We will ask you to
comment separately on different sections. The following list is very
similar to the rubric we will use when grading your final report.

1.0 Introduction. Is the introduction clear? Is the research question
specific and well defined? Does the introduction motivate a specific
concept to be measured and explain how it will be operationalized. Does
it do a good job of preparing the reader to understand the model
specifications?

2.0 The Initial Data Loading and Cleaning. Did the team notice any
anomalous values? Is there a sufficient justification for any data
points that are removed? Did the report note any coding features that
affect the meaning of variables (e.g. top-coding or bottom-coding)?
Overall, does the report demonstrate a thorough understanding of the
data?

3.0 The Model Building Process. Overall, is each step in the model
building process supported by EDA? Is the outcome variable (or
variables) appropriate? Is there a thorough univariate analysis of the
outcome variable? Did the team identify one, or a few, explanatory
variables and perform a thorough univariate analysis of each one? Did
the team clearly state why they chose these explanatory variables, does
this explanation make sense in term of their research question? Did the
team consider available variable transformations and select them with an
eye towards model plausibility and interperability? Are transformations
used to expose linear relationships in scatterplots? Is there enough
explanation in the text to understand the meaning of each visualization?

4.0 Regression Models: Base Model. Does this model only include key
explanatory variables? Do the variables make sense given the measurement
goals? Did the team apply reasonable transformations to these variables,
to capture the nature of the relationships?

4.1 Regression Model: Second Model. Does this model represent a balanced
approach, including variables that advance modeling goals without
causing major issues? Does the model suceed in reducing standard errors
of the key variables compared to the base model? Does it capture major
nonlinearities in the joint distribution of the variables?

4.2 Regression Model: Third Model. Does this model represent a
maximalist approach, erring on the side of including most variables? Is
it still a reasonable model? Are there any variables that are outcomes,
and should therefore still be excluded? Is there too much
multicolinearity, to the point that the key causal effects cannot be
measured?

4.3 Assessment of the CLM. Has the team assessed each of the CLM
assumptions (including random sampling)? Did they use visual tools or
statistical tests, as appropriate? Did they respond appropriately to any
violations?

4.4 The Regression Table. Are the model specifications properly chosen
to outline the boundary of reasonable choices? Is it easy to find key
coefficients in the regression table? Does the text include a discussion
of practical significance for key effects?

5.0 The Omitted Variables Discussion. Did the report miss any important
sources of omitted variable bias? Are the estimated directions of bias
correct? Was their explanation clear? Is the discussion connected to
whether the key effects are real or whether they may be solely an
artifact of omitted variable bias?

6.0 Conclusion. Does the conclusion address the high-level concerns of a
political campaign? Does it raise interesting points beyond numerical
estimates? Does it place relevant context around the results?

7.0 Can you find any other errors, faulty logic, unclear or unpersuasive
writing, or other elements that leave you less convinced by the
conclusions?

Please be thorough and read the report critically, actively trying to
find weaknesses. Your comments will directly help your peers get the
most value out of the project.
